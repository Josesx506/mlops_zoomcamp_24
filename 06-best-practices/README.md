### Unit tests
Test individual functions

### Integration tests
Test entire pipelines e.g writing to db and all endpoints with docker and bash scripting

`pipenv run pytest <test_dir>/` or `pytest <test_dir>/`


### LocalStack
[LocalStack](https://github.com/localstack/localstack) is an emulator to test AWS services locally. In this case, we"re simulating a kinesis stream. If you check existing streams with `aws kinesis list-streams`, it"ll be empty but you can simulate an AWS steam. 
1. Navigate to the `localstack` directory.
2. Export the environment variables and spin up the localstack kinesis instance from docker-compose.
    ```bash
    # Export environment variables that will be referenced in docker-compose
    export LOCAL_IMAGE_NAME=123
    export PREDICTIONS_STREAM_NAME=ride_predictions
    docker-compose up kinesis -d
    ```
3. Create a new stream named `ride_predictions` in localstack with 
    ```bash
    aws --endpoint-url=http://localhost:4568/ kinesis create-stream \
        --stream-name ride_predictions \
        --shard-count 1
    ```
4. View existing localstack streams with `aws --endpoint-url=http://localhost:4568/ kinesis list-streams`
5. Include the name of the aws service pointing to localstack in the docker-compose file `- KINESIS_ENDPOINT_URL=http://kinesis:4568/`
6. With bash and localStack, we can create integration tests to write to AWS kinesis stream and simulate how the data is read by our systems.

#### Read data from the Stream
1. Specify a shard id as the first shard since we created only 1
2. After running the test and inserting a message into the stream, read the shard iterator.
3. Extract the json as a base64 encoded message into the `${RESULT}` variable.
4. Decode the message.

    ```bash
    export SHARD="shardId-000000000000"

    SHARD_ITERATOR=$(aws --endpoint-url=http://localhost:4568/ kinesis \
        get-shard-iterator \
            --shard-id ${SHARD} \
            --shard-iterator-type TRIM_HORIZON \
            --stream-name ${PREDICTIONS_STREAM_NAME} \
            --query "ShardIterator" \
    )

    RESULT=$(aws --endpoint-url=http://localhost:4568/ \
        kinesis get-records --shard-iterator $SHARD_ITERATOR)

    echo ${RESULT} | jq -r ".Records[0].Data" | base64 --decode
    ```

#### Using localstack with boto3 in a python script
If the kinesis stream is working in docker, the endpoint environment variable can be used in a python script.
```python
kinesis_endpoint = os.getenv("KINESIS_ENDPOINT_URL", "http://localhost:4568/")
kinesis_client = boto3.client("kinesis", endpoint_url=kinesis_endpoint)
s3_client = boto3.client("s3", endpoint_url=kinesis_endpoint)
```
Other examples like setting up a [mock-s3 bucket](https://docs.localstack.cloud/user-guide/aws/s3/) is shown here


### Linting, Formatting, and Sorting
Linting can be configured globally in a `pyproject.toml` file or locally as a comment below classes/methods/functions. It can also be set at the top of a script to disable specific warnings for the entire script. 
```python
# Disabling pylint warning locally on a single function
def lambda_handler(event, context):
    #pylint: disable=unused-argument
    return model_service.lambda_handler(event)
```
In terminal, it can be run using `pylint --recursive=y .` within the root directory of a repo to check for lint warnings. <br>
Code formatting like removing trailing whitespaces can be done with the `black` package, while imports can be sorted with the `isort` package. Like pylint, black can be run from the terminal. View file differences with `black --diff . | less` to view some of the changes it proposes in files before executing the changes. It's also good to commit changes for working code before initiating black's formatting. Apply the changes by running `black .` in terminal. <br>
Like black, isort also allows you to view proposed changes with `isort --diff . | less`. It helps to sort imports within files and reduce errors on import hierarchy. Apply the changes by running `isort .` in terminal. <br>


- pyproject.toml global config example
    ```bash
    [tool.pylint]
    disable = [
        "missing-function-docstring",
        "missing-final-newline",
        "unused-argument"
    ]

    [tool.black]
    line-length = 88
    target-version = ["py39"] # python 3.9
    skip-string-normalization = true

    [tool.isort]
    multi_line_output = 3
    length_sort = true # sort shortest imports at the top like os 
    # and insert longer imports below shorter imports
    ```

Order of running in CI/CD
1. Sorting
2. Formatting
3. Linting
4. Tests

### Pre-commit Hooks
There's a python package name `pre-commit`. In git repo folders, there's a `.git/hooks` directory where we can see example of pre-commit shell files.  After installing it as `--dev` dependency, a sample config file can be generated by executing `pre-commit sample-config` from the root directory of a repo. Typically the pre-commit is saved in a **`.pre-commit-config.yaml`**. We can pipe the sample-config output to create a pre-commit starter file with 
```bash
pre-commit sample-config > .pre-commit-config.yaml
```
When a repo is created or cloned for the first time, the pre-commit hooks are not automatically installed and need to be initiated only once. Navigate to the `.git/` directory and run `pre-commit install` which creates a *pre-commit* file inside the `.git/hooks/pre-commit` folder. Now when files are added and committed, the pre-commit hook checks and modifies files with tools like isort and black. If it fails the pre-commit tests, some files are modified and need to be added again after changes have been fixed before final commits are made. If you google *isort/black/pytest precommit*, you can see the synthax for adding them to pre-commit files. You can also include arguments like package versions or specific pytest folders within the config file.

### Makefiles
Makefiles are like key-value pair of alias and terminal commands. In the example below, we want the command `echo 123` to print to terminal when the alias `make run` is called.
```bash
run:
    echo 123
```
The make program is installed by default on mac/linux but needs to be installed on Windows. Specific aliases can be made to depend on previous aliases e.g running pytests before deploying a ML webapp.
```bash
test:
    echo test1

run: test
    echo run
```
In fortran/C programs, `make clean` can be used to remove executables. An alias can depend on more than prior alias. Make files can be used to run `unittests -> integration tests -> sorting/formatting/linting -> creating a docker image` as part of a continuous pipeline. <br>
Local variables in a makefile can be defined to avoid an object like date changing from the top to the bottom of the file as different stepsa are executed.
```bash
LOCAL_TAG:=$(shell date + "%Y-%m-%d-%H-%M-%S")
```